user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 10M;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript 
               application/json application/javascript application/xml+rss;

    # ========== RATE LIMITING ZONES - DDoS Protection ==========
    # General API rate limit: 100 requests/sec per IP
    limit_req_zone $binary_remote_addr zone=general_limit:10m rate=100r/s;
    
    # Strict rate limit: 10 requests/sec per IP (for login, key generation)
    limit_req_zone $binary_remote_addr zone=strict_limit:10m rate=10r/s;
    
    # Per-API-key rate limit: 1000 requests/sec per key
    limit_req_zone $http_x_api_key zone=api_key_limit:10m rate=1000r/s;

    # ========== SESSION PERSISTENCE (Sticky Sessions) ==========
    # Hash-based session persistence for stateful connections
    map $remote_addr $session_route {
        default "";
    }
    
    upstream backend_servers_sticky {
        ip_hash;  # Route same IP to same backend (session persistence)
        
        # Backend Instance 1
        server backend1.internal:5000 max_fails=3 fail_timeout=10s weight=1;
        
        # Backend Instance 2
        server backend2.internal:5000 max_fails=3 fail_timeout=10s weight=1;
        
        # Backend Instance 3
        server backend3.internal:5000 max_fails=3 fail_timeout=10s weight=1;
    }

    # ========== UPSTREAM DEFINITION: Backend Servers ==========
    upstream backend_servers {
        least_conn;  # Load balancing method: distribute to server with fewest active connections
        
        # Backend Instance 1
        server backend1.internal:5000 max_fails=3 fail_timeout=10s weight=1;
        
        # Backend Instance 2
        server backend2.internal:5000 max_fails=3 fail_timeout=10s weight=1;
        
        # Backend Instance 3
        server backend3.internal:5000 max_fails=3 fail_timeout=10s weight=1;
        
        # Explanation:
        # max_fails=3     - Remove server after 3 failed requests
        # fail_timeout=10s - Try again after 10 seconds
        # weight=1        - Equal distribution (change to 2,3 for weighted)
        # least_conn      - Route new requests to server with fewest active connections
    }

    # ========== HTTP SERVER: Redirect to HTTPS (Production) ==========
    server {
        listen 80;
        server_name _;
        
        # For Let's Encrypt ACME challenges
        location /.well-known/acme-challenge/ {
            root /var/www/certbot;
        }
        
        # Redirect all HTTP to HTTPS (production only)
        # Uncomment in production after getting SSL certificate
        # location / {
        #     return 301 https://$server_name$request_uri;
        # }
    }

    # ========== HTTPS SERVER: Main API Server ==========
    # In production, add SSL certificate paths:
    # server {
    #     listen 443 ssl http2;
    #     ssl_certificate /etc/letsencrypt/live/api.example.com/fullchain.pem;
    #     ssl_certificate_key /etc/letsencrypt/live/api.example.com/privkey.pem;
    # }

    # For development (HTTP only)
    server {
        listen 80;
        server_name localhost 127.0.0.1;

        # ========== LOGGING ==========
        access_log /var/log/nginx/boltlink_access.log main;
        error_log /var/log/nginx/boltlink_error.log warn;

        # ========== HEALTH CHECK ENDPOINT - For Monitoring ==========
        location /health {
            access_log off;  # Don't log health checks to reduce noise
            proxy_pass http://backend_servers;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_connect_timeout 5s;
            proxy_send_timeout 5s;
            proxy_read_timeout 5s;
        }

        # ========== STRICT RATE LIMITING: Sensitive Endpoints ==========
        # Login, key generation, account changes - strict 10 req/sec per IP
        location ~ ^/(auth/login|auth/register|api/keys/generate|settings)$ {
            limit_req zone=strict_limit burst=20 nodelay;
            limit_req_status 429;
            
            # Use sticky sessions for authentication
            proxy_pass http://backend_servers_sticky;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            add_header X-RateLimit-Limit "10" always;
            add_header X-RateLimit-Remaining $limit_req_status always;
            add_header X-RateLimit-Zone "strict_limit" always;
        }

        # ========== API KEY RATE LIMITING ==========
        # Per-API-key rate limit for analytics and data endpoints
        location ~ ^/api/(analytics|links|campaigns|clicks)/ {
            limit_req zone=api_key_limit burst=100 nodelay;
            limit_req_status 429;
            
            proxy_pass http://backend_servers;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            
            proxy_connect_timeout 10s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            add_header X-RateLimit-Limit "1000" always;
            add_header X-RateLimit-Remaining $limit_req_status always;
            add_header X-RateLimit-Zone "api_key_limit" always;
        }

        # ========== API ROUTES - Everything else ==========
        location / {
            # General rate limiting: 100 req/sec per IP
            limit_req zone=general_limit burst=200 nodelay;
            limit_req_status 429;
            
            # Proxy settings
            proxy_pass http://backend_servers;
            proxy_http_version 1.1;
            
            # Keep-alive connection pooling
            proxy_set_header Connection "";
            
            # Forward client information
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            
            # Timeouts
            proxy_connect_timeout 10s;      # Connection timeout
            proxy_send_timeout 30s;         # Send timeout
            proxy_read_timeout 30s;         # Read timeout
            
            # Buffering
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            proxy_busy_buffers_size 8k;
            
            # Rate limiting headers
            add_header X-RateLimit-Limit "100" always;
            add_header X-RateLimit-Remaining $limit_req_status always;
            add_header X-RateLimit-Zone "general_limit" always;
            
            # Custom headers for debugging
            add_header X-Upstream $upstream_addr always;
            add_header X-Upstream-Status $upstream_status always;
            
            # Retry logic: if backend returns error, try next
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 10s;
        }

        # ========== STATIC FILES (if needed) ==========
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1d;
            access_log off;
            add_header Cache-Control "public, immutable";
        }

        # ========== STATUS PAGE (internal only) ==========
        location /nginx_status {
            stub_status on;
            access_log off;
            # Restrict to local only
            allow 127.0.0.1;
            allow 192.168.0.0/16;  # Allow from internal network
            deny all;
        }

        # ========== DENY ACCESS TO SENSITIVE FILES ==========
        location ~ /\. {
            deny all;
            access_log off;
            log_not_found off;
        }

        location ~ ~$ {
            deny all;
            access_log off;
            log_not_found off;
        }
    }
}
